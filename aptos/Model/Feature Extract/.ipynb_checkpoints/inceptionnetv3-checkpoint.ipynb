{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22b1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms \n",
    "from torchvision import models as m\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc  #garbage collector\n",
    "from torchinfo import summary\n",
    "from timm.models.vision_transformer import VisionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780a30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be76efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'AlexNet_Weights',\n",
       " 'ConvNeXt',\n",
       " 'ConvNeXt_Base_Weights',\n",
       " 'ConvNeXt_Large_Weights',\n",
       " 'ConvNeXt_Small_Weights',\n",
       " 'ConvNeXt_Tiny_Weights',\n",
       " 'DenseNet',\n",
       " 'DenseNet121_Weights',\n",
       " 'DenseNet161_Weights',\n",
       " 'DenseNet169_Weights',\n",
       " 'DenseNet201_Weights',\n",
       " 'EfficientNet',\n",
       " 'EfficientNet_B0_Weights',\n",
       " 'EfficientNet_B1_Weights',\n",
       " 'EfficientNet_B2_Weights',\n",
       " 'EfficientNet_B3_Weights',\n",
       " 'EfficientNet_B4_Weights',\n",
       " 'EfficientNet_B5_Weights',\n",
       " 'EfficientNet_B6_Weights',\n",
       " 'EfficientNet_B7_Weights',\n",
       " 'EfficientNet_V2_L_Weights',\n",
       " 'EfficientNet_V2_M_Weights',\n",
       " 'EfficientNet_V2_S_Weights',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'GoogLeNet_Weights',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'Inception_V3_Weights',\n",
       " 'MNASNet',\n",
       " 'MNASNet0_5_Weights',\n",
       " 'MNASNet0_75_Weights',\n",
       " 'MNASNet1_0_Weights',\n",
       " 'MNASNet1_3_Weights',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'MobileNet_V2_Weights',\n",
       " 'MobileNet_V3_Large_Weights',\n",
       " 'MobileNet_V3_Small_Weights',\n",
       " 'RegNet',\n",
       " 'RegNet_X_16GF_Weights',\n",
       " 'RegNet_X_1_6GF_Weights',\n",
       " 'RegNet_X_32GF_Weights',\n",
       " 'RegNet_X_3_2GF_Weights',\n",
       " 'RegNet_X_400MF_Weights',\n",
       " 'RegNet_X_800MF_Weights',\n",
       " 'RegNet_X_8GF_Weights',\n",
       " 'RegNet_Y_128GF_Weights',\n",
       " 'RegNet_Y_16GF_Weights',\n",
       " 'RegNet_Y_1_6GF_Weights',\n",
       " 'RegNet_Y_32GF_Weights',\n",
       " 'RegNet_Y_3_2GF_Weights',\n",
       " 'RegNet_Y_400MF_Weights',\n",
       " 'RegNet_Y_800MF_Weights',\n",
       " 'RegNet_Y_8GF_Weights',\n",
       " 'ResNeXt101_32X8D_Weights',\n",
       " 'ResNeXt101_64X4D_Weights',\n",
       " 'ResNeXt50_32X4D_Weights',\n",
       " 'ResNet',\n",
       " 'ResNet101_Weights',\n",
       " 'ResNet152_Weights',\n",
       " 'ResNet18_Weights',\n",
       " 'ResNet34_Weights',\n",
       " 'ResNet50_Weights',\n",
       " 'ShuffleNetV2',\n",
       " 'ShuffleNet_V2_X0_5_Weights',\n",
       " 'ShuffleNet_V2_X1_0_Weights',\n",
       " 'ShuffleNet_V2_X1_5_Weights',\n",
       " 'ShuffleNet_V2_X2_0_Weights',\n",
       " 'SqueezeNet',\n",
       " 'SqueezeNet1_0_Weights',\n",
       " 'SqueezeNet1_1_Weights',\n",
       " 'SwinTransformer',\n",
       " 'Swin_B_Weights',\n",
       " 'Swin_S_Weights',\n",
       " 'Swin_T_Weights',\n",
       " 'VGG',\n",
       " 'VGG11_BN_Weights',\n",
       " 'VGG11_Weights',\n",
       " 'VGG13_BN_Weights',\n",
       " 'VGG13_Weights',\n",
       " 'VGG16_BN_Weights',\n",
       " 'VGG16_Weights',\n",
       " 'VGG19_BN_Weights',\n",
       " 'VGG19_Weights',\n",
       " 'ViT_B_16_Weights',\n",
       " 'ViT_B_32_Weights',\n",
       " 'ViT_H_14_Weights',\n",
       " 'ViT_L_16_Weights',\n",
       " 'ViT_L_32_Weights',\n",
       " 'VisionTransformer',\n",
       " 'Wide_ResNet101_2_Weights',\n",
       " 'Wide_ResNet50_2_Weights',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_api',\n",
       " '_meta',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'feature_extraction',\n",
       " 'get_weight',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_transformer',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7928fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(1412)\n",
    "torch.cuda.manual_seed_all(1412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7d0062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Anaconda1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to C:\\Users\\22394/.cache\\torch\\hub\\checkpoints\\inception_v3_google-0cc3c7bd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ae1c482a1046779a9a7c673204df00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/104M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#执行此代码时注意关闭VPN\n",
    "IncV3 = m.inception_v3(pretrained=True) #resnet18_pretrained\n",
    "#将导入的预训练模型中所有的参数锁住\n",
    "for param in IncV3.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "400a3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = IncV3.fc.in_features  # 获取低级特征维度\n",
    "IncV3.fc = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c8b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\22394/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5fa82ba89a440eb69f579d32bed10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#执行此代码时注意关闭VPN\n",
    "Res50 = m.resnet50(pretrained=True) #resnet18_pretrained\n",
    "#将导入的预训练模型中所有的参数锁住\n",
    "for param in Res50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6faa3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = IncV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bc1430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Inception3                               [10, 4]                   3,326,696\n",
       "├─BasicConv2d: 1-1                       [10, 32, 111, 111]        --\n",
       "│    └─Conv2d: 2-1                       [10, 32, 111, 111]        (864)\n",
       "│    └─BatchNorm2d: 2-2                  [10, 32, 111, 111]        (64)\n",
       "├─BasicConv2d: 1-2                       [10, 32, 109, 109]        --\n",
       "│    └─Conv2d: 2-3                       [10, 32, 109, 109]        (9,216)\n",
       "│    └─BatchNorm2d: 2-4                  [10, 32, 109, 109]        (64)\n",
       "├─BasicConv2d: 1-3                       [10, 64, 109, 109]        --\n",
       "│    └─Conv2d: 2-5                       [10, 64, 109, 109]        (18,432)\n",
       "│    └─BatchNorm2d: 2-6                  [10, 64, 109, 109]        (128)\n",
       "├─MaxPool2d: 1-4                         [10, 64, 54, 54]          --\n",
       "├─BasicConv2d: 1-5                       [10, 80, 54, 54]          --\n",
       "│    └─Conv2d: 2-7                       [10, 80, 54, 54]          (5,120)\n",
       "│    └─BatchNorm2d: 2-8                  [10, 80, 54, 54]          (160)\n",
       "├─BasicConv2d: 1-6                       [10, 192, 52, 52]         --\n",
       "│    └─Conv2d: 2-9                       [10, 192, 52, 52]         (138,240)\n",
       "│    └─BatchNorm2d: 2-10                 [10, 192, 52, 52]         (384)\n",
       "├─MaxPool2d: 1-7                         [10, 192, 25, 25]         --\n",
       "├─InceptionA: 1-8                        [10, 256, 25, 25]         --\n",
       "│    └─BasicConv2d: 2-11                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-1                  [10, 64, 25, 25]          (12,288)\n",
       "│    │    └─BatchNorm2d: 3-2             [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-12                 [10, 48, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-3                  [10, 48, 25, 25]          (9,216)\n",
       "│    │    └─BatchNorm2d: 3-4             [10, 48, 25, 25]          (96)\n",
       "│    └─BasicConv2d: 2-13                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-5                  [10, 64, 25, 25]          (76,800)\n",
       "│    │    └─BatchNorm2d: 3-6             [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-14                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-7                  [10, 64, 25, 25]          (12,288)\n",
       "│    │    └─BatchNorm2d: 3-8             [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-15                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-9                  [10, 96, 25, 25]          (55,296)\n",
       "│    │    └─BatchNorm2d: 3-10            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-16                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-11                 [10, 96, 25, 25]          (82,944)\n",
       "│    │    └─BatchNorm2d: 3-12            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-17                 [10, 32, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-13                 [10, 32, 25, 25]          (6,144)\n",
       "│    │    └─BatchNorm2d: 3-14            [10, 32, 25, 25]          (64)\n",
       "├─InceptionA: 1-9                        [10, 288, 25, 25]         --\n",
       "│    └─BasicConv2d: 2-18                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-15                 [10, 64, 25, 25]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-16            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-19                 [10, 48, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-17                 [10, 48, 25, 25]          (12,288)\n",
       "│    │    └─BatchNorm2d: 3-18            [10, 48, 25, 25]          (96)\n",
       "│    └─BasicConv2d: 2-20                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-19                 [10, 64, 25, 25]          (76,800)\n",
       "│    │    └─BatchNorm2d: 3-20            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-21                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-21                 [10, 64, 25, 25]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-22            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-22                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-23                 [10, 96, 25, 25]          (55,296)\n",
       "│    │    └─BatchNorm2d: 3-24            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-23                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-25                 [10, 96, 25, 25]          (82,944)\n",
       "│    │    └─BatchNorm2d: 3-26            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-24                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-27                 [10, 64, 25, 25]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-28            [10, 64, 25, 25]          (128)\n",
       "├─InceptionA: 1-10                       [10, 288, 25, 25]         --\n",
       "│    └─BasicConv2d: 2-25                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-29                 [10, 64, 25, 25]          (18,432)\n",
       "│    │    └─BatchNorm2d: 3-30            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-26                 [10, 48, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-31                 [10, 48, 25, 25]          (13,824)\n",
       "│    │    └─BatchNorm2d: 3-32            [10, 48, 25, 25]          (96)\n",
       "│    └─BasicConv2d: 2-27                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-33                 [10, 64, 25, 25]          (76,800)\n",
       "│    │    └─BatchNorm2d: 3-34            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-28                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-35                 [10, 64, 25, 25]          (18,432)\n",
       "│    │    └─BatchNorm2d: 3-36            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-29                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-37                 [10, 96, 25, 25]          (55,296)\n",
       "│    │    └─BatchNorm2d: 3-38            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-30                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-39                 [10, 96, 25, 25]          (82,944)\n",
       "│    │    └─BatchNorm2d: 3-40            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-31                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-41                 [10, 64, 25, 25]          (18,432)\n",
       "│    │    └─BatchNorm2d: 3-42            [10, 64, 25, 25]          (128)\n",
       "├─InceptionB: 1-11                       [10, 768, 12, 12]         --\n",
       "│    └─BasicConv2d: 2-32                 [10, 384, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-43                 [10, 384, 12, 12]         (995,328)\n",
       "│    │    └─BatchNorm2d: 3-44            [10, 384, 12, 12]         (768)\n",
       "│    └─BasicConv2d: 2-33                 [10, 64, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-45                 [10, 64, 25, 25]          (18,432)\n",
       "│    │    └─BatchNorm2d: 3-46            [10, 64, 25, 25]          (128)\n",
       "│    └─BasicConv2d: 2-34                 [10, 96, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-47                 [10, 96, 25, 25]          (55,296)\n",
       "│    │    └─BatchNorm2d: 3-48            [10, 96, 25, 25]          (192)\n",
       "│    └─BasicConv2d: 2-35                 [10, 96, 12, 12]          --\n",
       "│    │    └─Conv2d: 3-49                 [10, 96, 12, 12]          (82,944)\n",
       "│    │    └─BatchNorm2d: 3-50            [10, 96, 12, 12]          (192)\n",
       "├─InceptionC: 1-12                       [10, 768, 12, 12]         --\n",
       "│    └─BasicConv2d: 2-36                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-51                 [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-52            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-37                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-53                 [10, 128, 12, 12]         (98,304)\n",
       "│    │    └─BatchNorm2d: 3-54            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-38                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-55                 [10, 128, 12, 12]         (114,688)\n",
       "│    │    └─BatchNorm2d: 3-56            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-39                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-57                 [10, 192, 12, 12]         (172,032)\n",
       "│    │    └─BatchNorm2d: 3-58            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-40                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-59                 [10, 128, 12, 12]         (98,304)\n",
       "│    │    └─BatchNorm2d: 3-60            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-41                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-61                 [10, 128, 12, 12]         (114,688)\n",
       "│    │    └─BatchNorm2d: 3-62            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-42                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-63                 [10, 128, 12, 12]         (114,688)\n",
       "│    │    └─BatchNorm2d: 3-64            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-43                 [10, 128, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-65                 [10, 128, 12, 12]         (114,688)\n",
       "│    │    └─BatchNorm2d: 3-66            [10, 128, 12, 12]         (256)\n",
       "│    └─BasicConv2d: 2-44                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-67                 [10, 192, 12, 12]         (172,032)\n",
       "│    │    └─BatchNorm2d: 3-68            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-45                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-69                 [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-70            [10, 192, 12, 12]         (384)\n",
       "├─InceptionC: 1-13                       [10, 768, 12, 12]         --\n",
       "│    └─BasicConv2d: 2-46                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-71                 [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-72            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-47                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-73                 [10, 160, 12, 12]         (122,880)\n",
       "│    │    └─BatchNorm2d: 3-74            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-48                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-75                 [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-76            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-49                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-77                 [10, 192, 12, 12]         (215,040)\n",
       "│    │    └─BatchNorm2d: 3-78            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-50                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-79                 [10, 160, 12, 12]         (122,880)\n",
       "│    │    └─BatchNorm2d: 3-80            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-51                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-81                 [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-82            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-52                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-83                 [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-84            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-53                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-85                 [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-86            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-54                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-87                 [10, 192, 12, 12]         (215,040)\n",
       "│    │    └─BatchNorm2d: 3-88            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-55                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-89                 [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-90            [10, 192, 12, 12]         (384)\n",
       "├─InceptionC: 1-14                       [10, 768, 12, 12]         --\n",
       "│    └─BasicConv2d: 2-56                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-91                 [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-92            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-57                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-93                 [10, 160, 12, 12]         (122,880)\n",
       "│    │    └─BatchNorm2d: 3-94            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-58                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-95                 [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-96            [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-59                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-97                 [10, 192, 12, 12]         (215,040)\n",
       "│    │    └─BatchNorm2d: 3-98            [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-60                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-99                 [10, 160, 12, 12]         (122,880)\n",
       "│    │    └─BatchNorm2d: 3-100           [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-61                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-101                [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-102           [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-62                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-103                [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-104           [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-63                 [10, 160, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-105                [10, 160, 12, 12]         (179,200)\n",
       "│    │    └─BatchNorm2d: 3-106           [10, 160, 12, 12]         (320)\n",
       "│    └─BasicConv2d: 2-64                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-107                [10, 192, 12, 12]         (215,040)\n",
       "│    │    └─BatchNorm2d: 3-108           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-65                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-109                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-110           [10, 192, 12, 12]         (384)\n",
       "├─InceptionC: 1-15                       [10, 768, 12, 12]         --\n",
       "│    └─BasicConv2d: 2-66                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-111                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-112           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-67                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-113                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-114           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-68                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-115                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-116           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-69                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-117                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-118           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-70                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-119                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-120           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-71                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-121                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-122           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-72                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-123                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-124           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-73                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-125                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-126           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-74                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-127                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-128           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-75                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-129                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-130           [10, 192, 12, 12]         (384)\n",
       "├─InceptionD: 1-16                       [10, 1280, 5, 5]          --\n",
       "│    └─BasicConv2d: 2-76                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-131                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-132           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-77                 [10, 320, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-133                [10, 320, 5, 5]           (552,960)\n",
       "│    │    └─BatchNorm2d: 3-134           [10, 320, 5, 5]           (640)\n",
       "│    └─BasicConv2d: 2-78                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-135                [10, 192, 12, 12]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-136           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-79                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-137                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-138           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-80                 [10, 192, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-139                [10, 192, 12, 12]         (258,048)\n",
       "│    │    └─BatchNorm2d: 3-140           [10, 192, 12, 12]         (384)\n",
       "│    └─BasicConv2d: 2-81                 [10, 192, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-141                [10, 192, 5, 5]           (331,776)\n",
       "│    │    └─BatchNorm2d: 3-142           [10, 192, 5, 5]           (384)\n",
       "├─InceptionE: 1-17                       [10, 2048, 5, 5]          --\n",
       "│    └─BasicConv2d: 2-82                 [10, 320, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-143                [10, 320, 5, 5]           (409,600)\n",
       "│    │    └─BatchNorm2d: 3-144           [10, 320, 5, 5]           (640)\n",
       "│    └─BasicConv2d: 2-83                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-145                [10, 384, 5, 5]           (491,520)\n",
       "│    │    └─BatchNorm2d: 3-146           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-84                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-147                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-148           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-85                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-149                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-150           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-86                 [10, 448, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-151                [10, 448, 5, 5]           (573,440)\n",
       "│    │    └─BatchNorm2d: 3-152           [10, 448, 5, 5]           (896)\n",
       "│    └─BasicConv2d: 2-87                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-153                [10, 384, 5, 5]           (1,548,288)\n",
       "│    │    └─BatchNorm2d: 3-154           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-88                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-155                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-156           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-89                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-157                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-158           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-90                 [10, 192, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-159                [10, 192, 5, 5]           (245,760)\n",
       "│    │    └─BatchNorm2d: 3-160           [10, 192, 5, 5]           (384)\n",
       "├─InceptionE: 1-18                       [10, 2048, 5, 5]          --\n",
       "│    └─BasicConv2d: 2-91                 [10, 320, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-161                [10, 320, 5, 5]           (655,360)\n",
       "│    │    └─BatchNorm2d: 3-162           [10, 320, 5, 5]           (640)\n",
       "│    └─BasicConv2d: 2-92                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-163                [10, 384, 5, 5]           (786,432)\n",
       "│    │    └─BatchNorm2d: 3-164           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-93                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-165                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-166           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-94                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-167                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-168           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-95                 [10, 448, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-169                [10, 448, 5, 5]           (917,504)\n",
       "│    │    └─BatchNorm2d: 3-170           [10, 448, 5, 5]           (896)\n",
       "│    └─BasicConv2d: 2-96                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-171                [10, 384, 5, 5]           (1,548,288)\n",
       "│    │    └─BatchNorm2d: 3-172           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-97                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-173                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-174           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-98                 [10, 384, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-175                [10, 384, 5, 5]           (442,368)\n",
       "│    │    └─BatchNorm2d: 3-176           [10, 384, 5, 5]           (768)\n",
       "│    └─BasicConv2d: 2-99                 [10, 192, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-177                [10, 192, 5, 5]           (393,216)\n",
       "│    │    └─BatchNorm2d: 3-178           [10, 192, 5, 5]           (384)\n",
       "├─AdaptiveAvgPool2d: 1-19                [10, 2048, 1, 1]          --\n",
       "├─Dropout: 1-20                          [10, 2048, 1, 1]          --\n",
       "├─Linear: 1-21                           [10, 4]                   8,196\n",
       "==========================================================================================\n",
       "Total params: 25,120,460\n",
       "Trainable params: 8,196\n",
       "Non-trainable params: 25,112,264\n",
       "Total mult-adds (G): 28.36\n",
       "==========================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 743.73\n",
       "Params size (MB): 87.18\n",
       "Estimated Total Size (MB): 836.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net1,input_size=(10,3,224,224),depth=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2aa200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Res50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c3afca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [10, 1000]                --\n",
       "├─Conv2d: 1-1                            [10, 64, 112, 112]        (9,408)\n",
       "├─BatchNorm2d: 1-2                       [10, 64, 112, 112]        (128)\n",
       "├─ReLU: 1-3                              [10, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [10, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [10, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-1                   [10, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-1                  [10, 64, 56, 56]          (4,096)\n",
       "│    │    └─BatchNorm2d: 3-2             [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-3                    [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                  [10, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-5             [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-6                    [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-7                  [10, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-8             [10, 256, 56, 56]         (512)\n",
       "│    │    └─Sequential: 3-9              [10, 256, 56, 56]         (16,896)\n",
       "│    │    └─ReLU: 3-10                   [10, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-2                   [10, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-11                 [10, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-12            [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-13                   [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-14                 [10, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-15            [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-16                   [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-17                 [10, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-18            [10, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-19                   [10, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-3                   [10, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-20                 [10, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-21            [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-22                   [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-23                 [10, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-24            [10, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-25                   [10, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-26                 [10, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-27            [10, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-28                   [10, 256, 56, 56]         --\n",
       "├─Sequential: 1-6                        [10, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-4                   [10, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-29                 [10, 128, 56, 56]         (32,768)\n",
       "│    │    └─BatchNorm2d: 3-30            [10, 128, 56, 56]         (256)\n",
       "│    │    └─ReLU: 3-31                   [10, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-32                 [10, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-33            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-34                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-35                 [10, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-36            [10, 512, 28, 28]         (1,024)\n",
       "│    │    └─Sequential: 3-37             [10, 512, 28, 28]         (132,096)\n",
       "│    │    └─ReLU: 3-38                   [10, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-5                   [10, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-39                 [10, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-40            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-41                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-42                 [10, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-43            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-44                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-45                 [10, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-46            [10, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-47                   [10, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-6                   [10, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-48                 [10, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-49            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-50                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-51                 [10, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-52            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-53                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-54                 [10, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-55            [10, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-56                   [10, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-7                   [10, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-57                 [10, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-58            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-59                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-60                 [10, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-61            [10, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-62                   [10, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-63                 [10, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-64            [10, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-65                   [10, 512, 28, 28]         --\n",
       "├─Sequential: 1-7                        [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-8                   [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-66                 [10, 256, 28, 28]         (131,072)\n",
       "│    │    └─BatchNorm2d: 3-67            [10, 256, 28, 28]         (512)\n",
       "│    │    └─ReLU: 3-68                   [10, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-69                 [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-71                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-72                 [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-73            [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─Sequential: 3-74             [10, 1024, 14, 14]        (526,336)\n",
       "│    │    └─ReLU: 3-75                   [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-9                   [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-76                 [10, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-77            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-78                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-79                 [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-80            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-81                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-82                 [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-83            [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-84                   [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-10                  [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-85                 [10, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-86            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-87                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-88                 [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-89            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-90                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-91                 [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-92            [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-93                   [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-11                  [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-94                 [10, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-95            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-96                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-97                 [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-98            [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-99                   [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-100                [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-101           [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-102                  [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-12                  [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-103                [10, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-104           [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-105                  [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-106                [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-107           [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-108                  [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-109                [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-110           [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-111                  [10, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-13                  [10, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-112                [10, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-113           [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-114                  [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-115                [10, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-116           [10, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-117                  [10, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-118                [10, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-119           [10, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-120                  [10, 1024, 14, 14]        --\n",
       "├─Sequential: 1-8                        [10, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-14                  [10, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-121                [10, 512, 14, 14]         (524,288)\n",
       "│    │    └─BatchNorm2d: 3-122           [10, 512, 14, 14]         (1,024)\n",
       "│    │    └─ReLU: 3-123                  [10, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-124                [10, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-125           [10, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-126                  [10, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-127                [10, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-128           [10, 2048, 7, 7]          (4,096)\n",
       "│    │    └─Sequential: 3-129            [10, 2048, 7, 7]          (2,101,248)\n",
       "│    │    └─ReLU: 3-130                  [10, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-15                  [10, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-131                [10, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-132           [10, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-133                  [10, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-134                [10, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-135           [10, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-136                  [10, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-137                [10, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-138           [10, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-139                  [10, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-16                  [10, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-140                [10, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-141           [10, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-142                  [10, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-143                [10, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-144           [10, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-145                  [10, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-146                [10, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-147           [10, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-148                  [10, 2048, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [10, 2048, 1, 1]          --\n",
       "├─Linear: 1-10                           [10, 1000]                (2,049,000)\n",
       "==========================================================================================\n",
       "Total params: 25,557,032\n",
       "Trainable params: 0\n",
       "Non-trainable params: 25,557,032\n",
       "Total mult-adds (G): 40.89\n",
       "==========================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 1778.32\n",
       "Params size (MB): 102.23\n",
       "Estimated Total Size (MB): 1886.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net2,input_size=(10,3,224,224),depth=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f4737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience = 5, tol = 0.0005): #惯例地定义我们所需要的一切变量/属性\\\n",
    "        #当连续patience次迭代时，这一轮迭代的损失与历史最低损失之间的差值小于阈值时\n",
    "        #就触发提前停止\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.tol = tol #tolerance，累积5次都低于tol才会触发停止\n",
    "        self.counter = 0 #计数，计算现在已经累积了counter次\n",
    "        self.lowest_loss = None\n",
    "        self.early_stop = False #True - 提前停止，False - 不要提前停止\n",
    "    \n",
    "    def __call__(self,val_loss):\n",
    "        if self.lowest_loss == None: #这是第一轮迭代\n",
    "            self.lowest_loss = val_loss\n",
    "        elif self.lowest_loss - val_loss > self.tol:\n",
    "            self.lowest_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.lowest_loss - val_loss < self.tol:\n",
    "            self.counter += 1\n",
    "            print(\"\\t NOTICE: Early stopping counter {} of {}\".format(self.counter,self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                print('\\t NOTICE: Early Stopping Actived')\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n",
    "        #这一轮迭代的损失与历史最低损失之间的差 - 阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IterOnce(net,criterion,opt,x,y):\n",
    "    \"\"\"\n",
    "    对模型进行一次迭代的函数\n",
    "    \n",
    "    net: 实例化后的架构\n",
    "    criterion: 损失函数\n",
    "    opt: 优化算法\n",
    "    x: 这一个batch中所有的样本\n",
    "    y: 这一个batch中所有样本的真实标签\n",
    "    \"\"\"\n",
    "    sigma = net.forward(x)\n",
    "    loss = criterion(sigma,y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad(set_to_none=True) #比起设置梯度为0，让梯度为None会更节约内存\n",
    "    yhat = torch.max(sigma,1)[1]\n",
    "    correct = torch.sum(yhat == y)\n",
    "    return correct,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestOnce(net,criterion,x,y):\n",
    "    \"\"\"\n",
    "    对一组数据进行测试并输出测试结果的函数\n",
    "    \n",
    "    net: 经过训练后的架构\n",
    "    criterion：损失函数\n",
    "    x：要测试的数据的所有样本\n",
    "    y：要测试的数据的真实标签\n",
    "    \"\"\"\n",
    "    #对测试，一定要阻止计算图追踪\n",
    "    #这样可以节省很多内存，加速运算\n",
    "    with torch.no_grad(): \n",
    "        sigma = net.forward(x)\n",
    "        loss = criterion(sigma,y)\n",
    "        yhat = torch.max(sigma,1)[1]\n",
    "        correct = torch.sum(yhat == y)\n",
    "    return correct,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed747d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH):\n",
    "    \"\"\"\n",
    "    对模型进行训练，并在每个epoch后输出训练集和测试集上的准确率/损失\n",
    "    以实现对模型的监控\n",
    "    实现模型的保存\n",
    "    \n",
    "    参数说明：\n",
    "    net: 实例化后的网络\n",
    "    batchdata：使用Dataloader分割后的训练数据\n",
    "    testdata：使用Dataloader分割后的测试数据\n",
    "    criterion：所使用的损失函数\n",
    "    opt：所使用的优化算法\n",
    "    epochs：一共要使用完整数据集epochs次\n",
    "    tol：提前停止时测试集上loss下降的阈值，连续5次loss下降不超过tol就会触发提前停止\n",
    "    modelname：现在正在运行的模型名称，用于保存权重时作为文件名\n",
    "    PATH：将权重文件保存在path目录下\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    SamplePerEpoch = batchdata.dataset.__len__() #整个epoch里有多少个样本\n",
    "    allsamples = SamplePerEpoch*epochs\n",
    "    trainedsamples = 0\n",
    "    trainlosslist = []\n",
    "    testlosslist = []\n",
    "    early_stopping = EarlyStopping(tol=tol)\n",
    "    highestacc = None\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        net.train()\n",
    "        correct_train = 0\n",
    "        loss_train = 0\n",
    "        for batch_idx, (x, y) in enumerate(batchdata):\n",
    "             #non_blocking 非阻塞=True，表示允许多个线程同时占用一个资源\n",
    "            #一般来说，一段代码/数据占用一部分计算资源时，该资源是不对其他代码/数据开放的\n",
    "            #此时被占用的资源叫做临界资源，正在运行的代码/数据被叫做临界区\n",
    "            #设置non_blocking=True，相当于允许多个代码在临界资源上运行\n",
    "            #可以加速运算\n",
    "            x = x.to(device,non_blocking=True)\n",
    "            y = y.to(device,non_blocking=True).view(x.shape[0])\n",
    "           \n",
    "            correct, loss = IterOnce(net,criterion,opt,x,y)\n",
    "            trainedsamples += x.shape[0]\n",
    "            loss_train += loss\n",
    "            correct_train += correct\n",
    "            \n",
    "            if (batch_idx+1) % 125 == 0:\n",
    "                #现在进行到了哪个epoch\n",
    "                #现在训练到了多少个样本\n",
    "                #总共要训练多少个样本\n",
    "                #现在的训练的样本占总共需要训练的样本的百分比\n",
    "                print('Epoch{}:[{}/{}({:.0f}%)]'.format(epoch\n",
    "                                                       ,trainedsamples\n",
    "                                                       ,allsamples\n",
    "                                                       ,100*trainedsamples/allsamples))\n",
    "            \n",
    "        TrainAccThisEpoch = float(correct_train*100)/SamplePerEpoch\n",
    "        TrainLossThisEpoch = float(loss_train)/SamplePerEpoch #平均每个样本上的损失\n",
    "        trainlosslist.append(TrainLossThisEpoch)\n",
    "    \n",
    "       #清理GPU内存\n",
    "        del x,y,correct,loss,correct_train,loss_train\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "      \n",
    "    \n",
    "        #每次训练完一个epoch，就在测试集上验证一下模型现在的效果\n",
    "        net.eval()\n",
    "        loss_test = 0\n",
    "        correct_test = 0\n",
    "        loss_test = 0\n",
    "        TestSample = testdata.dataset.__len__()\n",
    "\n",
    "        for x,y in testdata:\n",
    "            x = x.to(device,non_blocking=True)\n",
    "            y = y.to(device,non_blocking=True).view(x.shape[0])\n",
    "           \n",
    "            correct, loss = TestOnce(net,criterion,x,y)\n",
    "            loss_test += loss\n",
    "            correct_test += correct\n",
    "\n",
    "        TestAccThisEpoch = float(correct_test * 100)/TestSample\n",
    "        TestLossThisEpoch = float(loss_test * 100)/TestSample\n",
    "        testlosslist.append(TestLossThisEpoch)\n",
    "        \n",
    "        del x,y,correct,loss,correct_test, loss_test\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #对每一个epoch，打印训练和测试的结果\n",
    "        #训练集上的损失，测试集上的损失，训练集上的准确率，测试集上的准确率\n",
    "        print(\"\\t Train Loss:{:.6f}, Test Loss:{:.6f}, Train Acc:{:.3f}%, Test Acc:{:.3f}%\".format(TrainLossThisEpoch\n",
    "                                                                                                  ,TestLossThisEpoch\n",
    "                                                                                                  ,TrainAccThisEpoch\n",
    "                                                                                                  ,TestAccThisEpoch))\n",
    "        \n",
    "        #如果测试集准确率出现新高/测试集loss出现新低，那我会保存现在的这一组权重\n",
    "#         if highestacc == None: #首次进行测试\n",
    "#             highestacc = TestAccThisEpoch\n",
    "#         if highestacc < TestAccThisEpoch:\n",
    "#             highestacc = TestAccThisEpoch\n",
    "#             torch.save(net.state_dict(),os.path.join(PATH,modelname+\".pt\"))\n",
    "#             print(\"\\t Weight Saved\")\n",
    "        \n",
    "        #提前停止\n",
    "        early_stop = early_stopping(TestLossThisEpoch)\n",
    "        if early_stop == \"True\":\n",
    "            break\n",
    "            \n",
    "    print(\"Complete\")\n",
    "    return trainlosslist, testlosslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_split_data(root: str, val_rate: float = 0.2):\n",
    "    random.seed(0)  # 保证随机结果可复现\n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    # 遍历文件夹，一个文件夹对应一个类别\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    # 排序，保证各平台顺序一致\n",
    "    flower_class.sort()\n",
    "    # 生成类别名称以及对应的数字索引\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    train_images_path = []  # 存储训练集的所有图片路径\n",
    "    train_images_label = []  # 存储训练集图片对应索引信息\n",
    "    val_images_path = []  # 存储验证集的所有图片路径\n",
    "    val_images_label = []  # 存储验证集图片对应索引信息\n",
    "    every_class_num = []  # 存储每个类别的样本总数\n",
    "    supported = [\".jpg\", \".JPG\", \".png\", \".PNG\"]  # 支持的文件后缀类型\n",
    "    # 遍历每个文件夹下的文件\n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        # 遍历获取supported支持的所有文件路径\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "        # 排序，保证各平台顺序一致\n",
    "        images.sort()\n",
    "        # 获取该类别对应的索引\n",
    "        image_class = class_indices[cla]\n",
    "        # 记录该类别的样本数量\n",
    "        every_class_num.append(len(images))\n",
    "        # 按比例随机采样验证样本\n",
    "        val_path = random.sample(images, k=int(len(images) * val_rate))\n",
    "\n",
    "        for img_path in images:\n",
    "            if img_path in val_path:  # 如果该路径在采样的验证集样本中则存入验证集\n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            else:  # 否则存入训练集\n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "    \n",
    "    plot_image = False\n",
    "    if plot_image:\n",
    "        # 绘制每种类别个数柱状图\n",
    "        plt.bar(range(len(flower_class)), every_class_num, align='center')\n",
    "        # 将横坐标0,1,2,3,4替换为相应的类别名称\n",
    "        plt.xticks(range(len(flower_class)), flower_class)\n",
    "        # 在柱状图上添加数值标签\n",
    "        for i, v in enumerate(every_class_num):\n",
    "            plt.text(x=i, y=v + 5, s=str(v), ha='center')\n",
    "        # 设置x坐标\n",
    "        plt.xlabel('image class')\n",
    "        # 设置y坐标\n",
    "        plt.ylabel('number of images')\n",
    "        # 设置柱状图的标题\n",
    "        plt.title('flower class distribution')\n",
    "        plt.show()\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet():\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, images_path: list, images_class: list, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item])\n",
    "        # RGB为彩色图片，L为灰度图片\n",
    "        if img.mode != 'RGB':\n",
    "            raise ValueError(\"image: {} isn't RGB mode.\".format(self.images_path[item]))\n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images, labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"F:\\torchstudy\\自建架构\\image_224_transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "data_transform = {\n",
    "        \"train\": transforms.Compose([\n",
    "#                                      transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([\n",
    "#                                  transforms.Resize(int(img_size * 1.143)),\n",
    "#                                    transforms.CenterCrop(img_size),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "# 实例化训练数据集\n",
    "train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                               transform=data_transform[\"train\"]\n",
    "                         )\n",
    "\n",
    "# 实例化验证数据集\n",
    "val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                           transform=data_transform[\"val\"]\n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_procedure(net,epochs,bs,modelname, PATH, lr=0.001,alpha=0.99,gamma=0,wd=0,tol=10**(-5)):\n",
    "    \n",
    "    torch.manual_seed(1412)\n",
    "    \n",
    "    #分割数据\n",
    "    batchdata = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=bs,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=0,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "    testdata =torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=bs,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=0,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "    \n",
    "    #损失函数，优化算法\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"sum\") #进行损失函数计算时，最后输出结果的计算模式\n",
    "    opt = optim.RMSprop(net.parameters(),lr=lr\n",
    "                        ,alpha=alpha,momentum=gamma,weight_decay=wd)\n",
    "    \n",
    "    #训练与测试\n",
    "    trainloss, testloss = fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH)\n",
    "    \n",
    "    return trainloss, testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d712528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘图函数\n",
    "def plotloss(trainloss, testloss):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(trainloss, color=\"red\", label=\"Trainloss\")\n",
    "    plt.plot(testloss, color=\"orange\", label=\"Testloss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289225c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069112c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"MyNet3_0.001_train_2\"\n",
    "torch.manual_seed(420)\n",
    "model3 = MyNet3()\n",
    "PATH  =\"/home/ubuntu/fy/diabetic retinopathy/feature selection\"\n",
    "# model3.load_state_dict(torch.load(\"/home/ubuntu/fy/diabetic retinopathy/feature selection/MyNet3_0.001_train.pt\"))\n",
    "print(modelname)\n",
    "\n",
    "net = model3.to(device,non_blocking=True)\n",
    "trainloss3 = full_procedure(model3,200,128,modelname=modelname, PATH=PATH, lr=0.003,alpha=0.99,gamma=0.002,wd=0,tol=10**(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb7cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8f630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56b154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fef77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e792ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
