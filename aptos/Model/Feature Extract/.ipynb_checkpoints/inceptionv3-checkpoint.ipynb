{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be208d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d94fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms \n",
    "from torchvision import models as m\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc  #garbage collector\n",
    "from torchinfo import summary\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786fd72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8447072",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(1412)\n",
    "torch.cuda.manual_seed_all(1412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcbee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行此代码时注意关闭VPN\n",
    "IncV3 = m.inception_v3(pretrained=True) #resnet18_pretrained\n",
    "#将导入的预训练模型中所有的参数锁住\n",
    "for param in IncV3.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67521231",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = IncV3.fc.in_features  # 获取低级特征维度\n",
    "IncV3.fc = nn.Linear(num_ftrs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0f555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model =IncV3.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31616a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_split_data(root: str, val_rate: float = 0.2):\n",
    "    random.seed(0)  # 保证随机结果可复现\n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    # 遍历文件夹，一个文件夹对应一个类别\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    # 排序，保证各平台顺序一致\n",
    "    flower_class.sort()\n",
    "    # 生成类别名称以及对应的数字索引\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    train_images_path = []  # 存储训练集的所有图片路径\n",
    "    train_images_label = []  # 存储训练集图片对应索引信息\n",
    "    val_images_path = []  # 存储验证集的所有图片路径\n",
    "    val_images_label = []  # 存储验证集图片对应索引信息\n",
    "    every_class_num = []  # 存储每个类别的样本总数\n",
    "    supported = [\".jpg\", \".JPG\", \".png\", \".PNG\"]  # 支持的文件后缀类型\n",
    "    # 遍历每个文件夹下的文件\n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        # 遍历获取supported支持的所有文件路径\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "        # 排序，保证各平台顺序一致\n",
    "        images.sort()\n",
    "        # 获取该类别对应的索引\n",
    "        image_class = class_indices[cla]\n",
    "        # 记录该类别的样本数量\n",
    "        every_class_num.append(len(images))\n",
    "        # 按比例随机采样验证样本\n",
    "        val_path = random.sample(images, k=int(len(images) * val_rate))\n",
    "\n",
    "        for img_path in images:\n",
    "            if img_path in val_path:  # 如果该路径在采样的验证集样本中则存入验证集\n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            else:  # 否则存入训练集\n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "    \n",
    "    plot_image = False\n",
    "    if plot_image:\n",
    "        # 绘制每种类别个数柱状图\n",
    "        plt.bar(range(len(flower_class)), every_class_num, align='center')\n",
    "        # 将横坐标0,1,2,3,4替换为相应的类别名称\n",
    "        plt.xticks(range(len(flower_class)), flower_class)\n",
    "        # 在柱状图上添加数值标签\n",
    "        for i, v in enumerate(every_class_num):\n",
    "            plt.text(x=i, y=v + 5, s=str(v), ha='center')\n",
    "        # 设置x坐标\n",
    "        plt.xlabel('image class')\n",
    "        # 设置y坐标\n",
    "        plt.ylabel('number of images')\n",
    "        # 设置柱状图的标题\n",
    "        plt.title('flower class distribution')\n",
    "        plt.show()\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec253e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet():\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, images_path: list, images_class: list, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item])\n",
    "        # RGB为彩色图片，L为灰度图片\n",
    "        if img.mode != 'RGB':\n",
    "            raise ValueError(\"image: {} isn't RGB mode.\".format(self.images_path[item]))\n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images, labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9c0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ubuntu/fy/外部验证/aptos_data/aptos_ori_gro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c415592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662 images were found in the dataset.\n",
      "2931 images for training.\n",
      "731 images for validation.\n"
     ]
    }
   ],
   "source": [
    "train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e62a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "data_transform = {\n",
    "        \"train\": transforms.Compose([\n",
    "                                    transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"val\": transforms.Compose([\n",
    "                          transforms.Resize(299),\n",
    "                          transforms.CenterCrop(299),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "        ])}\n",
    "\n",
    "# 实例化训练数据集\n",
    "train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                               transform=data_transform[\"train\"]\n",
    "                         )\n",
    "\n",
    "# 实例化验证数据集\n",
    "val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                           transform=data_transform[\"val\"]\n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e1fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "batchdata = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               drop_last=True,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "\n",
    "testdata = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                            drop_last=True,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "\n",
    "dataloaders = {'train': batchdata , 'val': testdata }\n",
    "dataset_sizes = {'train': len( batchdata), 'val': len(testdata)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3cbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience = 5, tol = 0.0005): #惯例地定义我们所需要的一切变量/属性\\\n",
    "        #当连续patience次迭代时，这一轮迭代的损失与历史最低损失之间的差值小于阈值时\n",
    "        #就触发提前停止\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.tol = tol #tolerance，累积5次都低于tol才会触发停止\n",
    "        self.counter = 0 #计数，计算现在已经累积了counter次\n",
    "        self.lowest_loss = None\n",
    "        self.early_stop = True #True - 提前停止，False - 不要提前停止\n",
    "    \n",
    "    def __call__(self,val_loss):\n",
    "        if self.lowest_loss == None: #这是第一轮迭代\n",
    "            self.lowest_loss = val_loss\n",
    "        elif self.lowest_loss - val_loss > self.tol:\n",
    "            self.lowest_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.lowest_loss - val_loss < self.tol:\n",
    "            self.counter += 1\n",
    "            print(\"\\t NOTICE: Early stopping counter {} of {}\".format(self.counter,self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                print('\\t NOTICE: Early Stopping Actived')\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n",
    "        #这一轮迭代的损失与历史最低损失之间的差 - 阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27607544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IterOnce(net,criterion,opt,x,y):\n",
    "    \"\"\"\n",
    "    对模型进行一次迭代的函数\n",
    "    \n",
    "    net: 实例化后的架构\n",
    "    criterion: 损失函数\n",
    "    opt: 优化算法\n",
    "    x: 这一个batch中所有的样本\n",
    "    y: 这一个batch中所有样本的真实标签\n",
    "    \"\"\"\n",
    "    sigma = net.forward(x)\n",
    "    loss = criterion(sigma,y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad(set_to_none=True) #比起设置梯度为0，让梯度为None会更节约内存\n",
    "    yhat = torch.max(sigma,1)[1]\n",
    "    correct = torch.sum(yhat == y)\n",
    "    return correct,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c87ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IterOnce(net, criterion, opt, x, y):\n",
    "    outputs, _ = net(x)  # 假设模型输出是元组，_ 是辅助分类器的输出\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    yhat = torch.max(outputs, 1)[1]\n",
    "    correct = torch.sum(yhat == y)\n",
    "    return correct, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e650356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestOnce(net,criterion,x,y):\n",
    "    \"\"\"\n",
    "    对一组数据进行测试并输出测试结果的函数\n",
    "    \n",
    "    net: 经过训练后的架构\n",
    "    criterion：损失函数\n",
    "    x：要测试的数据的所有样本\n",
    "    y：要测试的数据的真实标签\n",
    "    \"\"\"\n",
    "    #对测试，一定要阻止计算图追踪\n",
    "    #这样可以节省很多内存，加速运算\n",
    "    with torch.no_grad(): \n",
    "        sigma = net.forward(x)\n",
    "        loss = criterion(sigma,y)\n",
    "        yhat = torch.max(sigma,1)[1]\n",
    "        correct = torch.sum(yhat == y)\n",
    "    return correct,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c00b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH):\n",
    "    \"\"\"\n",
    "    对模型进行训练，并在每个epoch后输出训练集和测试集上的准确率/损失\n",
    "    以实现对模型的监控\n",
    "    实现模型的保存\n",
    "    \n",
    "    参数说明：\n",
    "    net: 实例化后的网络\n",
    "    batchdata：使用Dataloader分割后的训练数据\n",
    "    testdata：使用Dataloader分割后的测试数据\n",
    "    criterion：所使用的损失函数\n",
    "    opt：所使用的优化算法\n",
    "    epochs：一共要使用完整数据集epochs次\n",
    "    tol：提前停止时测试集上loss下降的阈值，连续5次loss下降不超过tol就会触发提前停止\n",
    "    modelname：现在正在运行的模型名称，用于保存权重时作为文件名\n",
    "    PATH：将权重文件保存在path目录下\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    SamplePerEpoch = batchdata.dataset.__len__() #整个epoch里有多少个样本\n",
    "    allsamples = SamplePerEpoch*epochs\n",
    "    trainedsamples = 0\n",
    "    trainlosslist = []\n",
    "    testlosslist = []\n",
    "    early_stopping = EarlyStopping(tol=tol)\n",
    "    highestacc = None\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        net.train()\n",
    "        correct_train = 0\n",
    "        loss_train = 0\n",
    "        for batch_idx, (x, y) in enumerate(batchdata):\n",
    "             #non_blocking 非阻塞=True，表示允许多个线程同时占用一个资源\n",
    "            #一般来说，一段代码/数据占用一部分计算资源时，该资源是不对其他代码/数据开放的\n",
    "            #此时被占用的资源叫做临界资源，正在运行的代码/数据被叫做临界区\n",
    "            #设置non_blocking=True，相当于允许多个代码在临界资源上运行\n",
    "            #可以加速运算\n",
    "            x = x.to(device,non_blocking=True)\n",
    "            y = y.to(device,non_blocking=True).view(x.shape[0])\n",
    "           \n",
    "            correct, loss = IterOnce(net,criterion,opt,x,y)\n",
    "            trainedsamples += x.shape[0]\n",
    "            loss_train += loss\n",
    "            correct_train += correct\n",
    "            \n",
    "            if (batch_idx+1) % 125 == 0:\n",
    "                #现在进行到了哪个epoch\n",
    "                #现在训练到了多少个样本\n",
    "                #总共要训练多少个样本\n",
    "                #现在的训练的样本占总共需要训练的样本的百分比\n",
    "                print('Epoch{}:[{}/{}({:.0f}%)]'.format(epoch\n",
    "                                                       ,trainedsamples\n",
    "                                                       ,allsamples\n",
    "                                                       ,100*trainedsamples/allsamples))\n",
    "            \n",
    "        TrainAccThisEpoch = float(correct_train*100)/SamplePerEpoch\n",
    "        TrainLossThisEpoch = float(loss_train)/SamplePerEpoch #平均每个样本上的损失\n",
    "        trainlosslist.append(TrainLossThisEpoch)\n",
    "    \n",
    "       #清理GPU内存\n",
    "        del x,y,correct,loss,correct_train,loss_train\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "      \n",
    "    \n",
    "        #每次训练完一个epoch，就在测试集上验证一下模型现在的效果\n",
    "        net.eval()\n",
    "        loss_test = 0\n",
    "        correct_test = 0\n",
    "        loss_test = 0\n",
    "        TestSample = testdata.dataset.__len__()\n",
    "\n",
    "        for x,y in testdata:\n",
    "            x = x.to(device,non_blocking=True)\n",
    "            y = y.to(device,non_blocking=True).view(x.shape[0])\n",
    "           \n",
    "            correct, loss = TestOnce(net,criterion,x,y)\n",
    "            loss_test += loss\n",
    "            correct_test += correct\n",
    "\n",
    "        TestAccThisEpoch = float(correct_test * 100)/TestSample\n",
    "        TestLossThisEpoch = float(loss_test )/TestSample\n",
    "        testlosslist.append(TestLossThisEpoch)\n",
    "        \n",
    "        del x,y,correct,loss,correct_test, loss_test\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #对每一个epoch，打印训练和测试的结果\n",
    "        #训练集上的损失，测试集上的损失，训练集上的准确率，测试集上的准确率\n",
    "        print(\"\\t Train Loss:{:.6f}, Test Loss:{:.6f}, Train Acc:{:.3f}%, Test Acc:{:.3f}%\".format(TrainLossThisEpoch\n",
    "                                                                                                  ,TestLossThisEpoch\n",
    "                                                                                                  ,TrainAccThisEpoch\n",
    "                                                                                                  ,TestAccThisEpoch))\n",
    "        \n",
    "        #如果测试集准确率出现新高/测试集loss出现新低，那我会保存现在的这一组权重\n",
    "        if highestacc == None: #首次进行测试\n",
    "            highestacc = TestAccThisEpoch\n",
    "        if highestacc < TestAccThisEpoch:\n",
    "            highestacc = TestAccThisEpoch\n",
    "            torch.save(net.state_dict(),os.path.join(PATH,modelname+\".pt\"))\n",
    "#             torch.save(net.state_dict(), os.path.join(PATH, str(modelname) + \".pt\"))\n",
    "            print(\"\\t Weight Saved\")\n",
    "        \n",
    "        #提前停止\n",
    "        early_stop = early_stopping(TestLossThisEpoch)\n",
    "        if early_stop == \"True\":\n",
    "            break\n",
    "            \n",
    "    print(\"Complete\")\n",
    "    return trainlosslist, testlosslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b33a0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_procedure(net,epochs,bs,modelname, PATH, lr=0.001,alpha=0.99,gamma=0,wd=0,tol=10**(-5)):\n",
    "    \n",
    "    torch.manual_seed(1412)\n",
    "    \n",
    "    #分割数据\n",
    "    batchdata = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=bs,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               drop_last=True,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "    testdata =torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=bs,\n",
    "                                             drop_last=True,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             \n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "    \n",
    "    #损失函数，优化算法\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"sum\") #进行损失函数计算时，最后输出结果的计算模式\n",
    "    opt = optim.RMSprop(net.parameters(),lr=lr\n",
    "                        ,alpha=alpha,momentum=gamma,weight_decay=wd)\n",
    "    \n",
    "    #训练与测试\n",
    "    trainloss, testloss = fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH)\n",
    "    \n",
    "    return trainloss, testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a665c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘图函数\n",
    "def plotloss(trainloss, testloss):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(trainloss, color=\"red\", label=\"Trainloss\")\n",
    "    plt.plot(testloss, color=\"orange\", label=\"Testloss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a563406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3_1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 676.00 MiB (GPU 0; 11.77 GiB total capacity; 1.60 GiB already allocated; 509.50 MiB free; 3.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_508985/267589486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                      \u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                      \u001b[0;34m,\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                                      ) #wd非常敏感，因此要小心地进行调整\n\u001b[1;32m     16\u001b[0m \u001b[0mplotloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_508985/4042896505.py\u001b[0m in \u001b[0;36mfull_procedure\u001b[0;34m(net, epochs, bs, modelname, PATH, lr, alpha, gamma, wd, tol)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#训练与测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrainloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_508985/2275633431.py\u001b[0m in \u001b[0;36mfit_test\u001b[0;34m(net, batchdata, testdata, criterion, opt, epochs, tol, modelname, PATH)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterOnce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mtrainedsamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_508985/4252293014.py\u001b[0m in \u001b[0;36mIterOnce\u001b[0;34m(net, criterion, opt, x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIterOnce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 假设模型输出是元组，_ 是辅助分类器的输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0maux_defined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_2a_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# N x 32 x 147 x 147\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_2b_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m# N x 64 x 147 x 147\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 676.00 MiB (GPU 0; 11.77 GiB total capacity; 1.60 GiB already allocated; 509.50 MiB free; 3.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "modelname = \"inceptionv3_1\"\n",
    "torch.manual_seed(420)\n",
    "PATH  =\"/home/ubuntu/fy/外部验证/feature selection\"\n",
    "# model2.load_state_dict(torch.load(\"/home/ubuntu/jupyter notebook/MyNet2_0.001_1.pt\"))\n",
    "print(modelname)\n",
    "net = model.to(device,non_blocking=True)\n",
    "trainloss, testloss = full_procedure(net ,epochs=15, bs=128#令batch_size下降一半\n",
    "                                     ,modelname=modelname\n",
    "                                     ,PATH = PATH\n",
    "                                     ,lr = 0.001\n",
    "                                     ,alpha=0.99\n",
    "                                     ,gamma= 0.001\n",
    "                                     ,wd = 0\n",
    "                                     ,tol = 10**(-5)\n",
    "                                     ) #wd非常敏感，因此要小心地进行调整\n",
    "plotloss(trainloss,testloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc, cohen_kappa_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model.load_state_dict(torch.load(\"/home/ubuntu/fy/外部验证/feature selection/inceptionv3_1.pt\"))\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()   # 设置模型为评估模式\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    # 遍历数据\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "        \n",
    "    return true_labels, pred_labels\n",
    "\n",
    "# 获取预测和真实标签\n",
    "true_labels, pred_labels = evaluate_model(model, dataloaders['val'], device)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "predicted_classes = np.array(pred_labels )\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "confusion = confusion_matrix(true_labels, predicted_classes)\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "recall = recall_score(true_labels, predicted_classes, average='weighted')\n",
    "precision = precision_score(true_labels, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_classes, average='weighted')\n",
    "\n",
    "# Calculate Quadratic Weighted Kappa\n",
    "kappa = cohen_kappa_score(true_labels, predicted_classes, weights='quadratic')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Quadratic Weighted Kappa:\", kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d52d6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_ds\u001b[49m:\n\u001b[0;32m     33\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     34\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def plot_roc_micro(name, labels, predictions, class_names, **kwargs):\n",
    "    # Compute micro-average ROC curve and ROC AUC score\n",
    "    fpr, tpr, _ = metrics.roc_curve(pd.get_dummies(labels).values.ravel(), predictions.ravel())\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the micro-average ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=name+' (micro-average AUC = {0:.2f})'.format(roc_auc), linewidth=2, **kwargs)\n",
    "    plt.plot([0, 1], [0, 1], color='orange', linestyle='--')\n",
    "    plt.xlabel('False positives rate')\n",
    "    plt.ylabel('True positives rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# Assuming you have defined `class_names` as a list of four class names\n",
    "class_names = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\n",
    "\n",
    "val_pre_auc = []\n",
    "val_label_auc = []\n",
    "\n",
    "train_ds = dataloaders['train']\n",
    "val_ds = dataloaders['val']\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_ds:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predictions_auc = model(images)\n",
    "        val_pre_auc.append(predictions_auc.cpu().numpy())  # Output probabilities for all classes\n",
    "        val_label_auc.append(labels.cpu().numpy())\n",
    "\n",
    "val_pre_auc = np.vstack(val_pre_auc)\n",
    "val_label_auc = np.hstack(val_label_auc)\n",
    "\n",
    "plot_roc_micro('validation AUC', val_label_auc, val_pre_auc, class_names, color=\"red\", linestyle='--')\n",
    "\n",
    "# Compute the ROC AUC score for the validation set\n",
    "auc_score_val = metrics.roc_auc_score(pd.get_dummies(val_label_auc), val_pre_auc, multi_class='ovr')\n",
    "\n",
    "train_pre_auc = []\n",
    "train_label_auc = []\n",
    "\n",
    "model.train()  # Set the model back to training mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_ds:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predictions_auc = model(images)\n",
    "        train_pre_auc.append(predictions_auc.cpu().numpy())\n",
    "        train_label_auc.append(labels.cpu().numpy())\n",
    "\n",
    "train_pre_auc = np.vstack(train_pre_auc)\n",
    "train_label_auc = np.hstack(train_label_auc)\n",
    "\n",
    "plot_roc_micro('training AUC', train_label_auc, train_pre_auc, class_names, color=\"blue\", linestyle='--')\n",
    "\n",
    "# Compute the ROC AUC score for the training set\n",
    "auc_score_train = metrics.roc_auc_score(pd.get_dummies(train_label_auc), train_pre_auc, multi_class='ovr')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(\"训练集的AUC值为：\", auc_score_train, \"验证集的AUC值为：\", auc_score_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
